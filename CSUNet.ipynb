{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices=tf.compat.v1.config.experimental.list_physical_devices('GPU')\n",
    "print('GPU is available' if len(physical_devices) > 0 else 'Not available')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "np.random.seed(65)\n",
    "random.seed(65)\n",
    "tf.random.set_seed(65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gegenbauer_polynomial(x, degree, alpha):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    alpha = tf.cast(alpha, tf.float32)\n",
    "\n",
    "    C0 = tf.ones_like(x)\n",
    "    if degree == 0:\n",
    "        return C0\n",
    "\n",
    "    C1 = 2.0 * alpha * x\n",
    "    if degree == 1:\n",
    "        return C1\n",
    "\n",
    "    C_prev = C0\n",
    "    C_curr = C1\n",
    "    for n in range(2, degree + 1):\n",
    "        coef1 = 2.0 * (n + alpha - 1.0) / n\n",
    "        coef2 = (n + 2.0 * alpha - 2.0) / n\n",
    "        C_next = coef1 * x * C_curr - coef2 * C_prev\n",
    "        C_prev, C_curr = C_curr, C_next\n",
    "\n",
    "    return C_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GegenbauerNeuralBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, degree=5, **kwargs):\n",
    "        super(GegenbauerNeuralBlock, self).__init__(**kwargs)\n",
    "        self.degree = degree\n",
    "        self.gegenbauer_fn = tf.function(gegenbauer_polynomial)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.alpha = self.add_weight(\n",
    "            name=\"alpha\",\n",
    "            initializer=\"ones\",\n",
    "            shape=(1,),\n",
    "            trainable=True\n",
    "        )\n",
    "        super(GegenbauerNeuralBlock, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.keras.activations.sigmoid(inputs)\n",
    "        alpha = tf.keras.activations.softplus(self.alpha)  # ensures alpha > 0\n",
    "        return self.gegenbauer_fn(x, self.degree, alpha)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GegenbauerNeuralBlock, self).get_config()\n",
    "        config.update({\n",
    "            \"degree\": self.degree\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv2D, Conv2DTranspose, MaxPooling2D, \n",
    "                                     Concatenate, Activation, GlobalMaxPooling2D, Reshape, Multiply, Add)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "import tensorflow.keras.layers as KL\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Snake Activation ---\n",
    "class SnakeActivation(tf.keras.layers.Layer):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + (1.0 / self.alpha) * tf.math.sin(self.alpha * x) ** 2\n",
    "\n",
    "# --- DSConvTF: deformable conv layer ---\n",
    "class ConvGNRelu(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_ch, kernel_size, groups=16):\n",
    "        super().__init__()\n",
    "        self.out_ch = out_ch\n",
    "        self.kernel_size = kernel_size\n",
    "        self.groups = groups\n",
    "\n",
    "        # Layers created once\n",
    "        self.conv = Conv2D(out_ch, kernel_size, padding='same', use_bias=False)\n",
    "        self.gn = tfa.layers.GroupNormalization(groups=groups, axis=-1)\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Placeholder deformable conv: simply apply conv for now\n",
    "        deformed = x  # You can replace with actual deformable offsets\n",
    "        x = self.conv(deformed)\n",
    "        x = self.gn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# --- Dynamic Snake Conv2D ---\n",
    "class DynamicSnakeConv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, groups=16):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.groups = groups\n",
    "        self.dsconv = ConvGNRelu(filters, kernel_size, groups=groups)\n",
    "        self.snake = SnakeActivation()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dsconv(x)\n",
    "        x = self.snake(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"groups\": self.groups,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# ------------------- SE-Net with DenseKAN and FJNB -------------------\n",
    "def se_net(x, r=8):\n",
    "    input_channel = x.shape[-1]\n",
    "    squeeze = GlobalMaxPooling2D()(x)\n",
    "    squeeze = Reshape((1, 1, input_channel))(squeeze)\n",
    "\n",
    "    excitation = KL.Dense(input_channel // r)(squeeze)\n",
    "    \n",
    "    excitation = Activation('relu')(excitation)\n",
    "    excitation = GegenbauerNeuralBlock(5)(excitation)\n",
    "    \n",
    "\n",
    "    excitation = KL.Dense(input_channel)(excitation)\n",
    "    \n",
    "    excitation = Activation('sigmoid')(excitation)\n",
    "    excitation = GegenbauerNeuralBlock(5)(excitation)\n",
    "\n",
    "    scaled = Multiply()([x, excitation])\n",
    "    return scaled\n",
    "\n",
    "# ------------------- Feature Selective Fusion Block -------------------\n",
    "def fsf_block(low_x, high_x):\n",
    "    merged = Concatenate()([high_x, low_x])\n",
    "    attention = se_net(merged)\n",
    "    fused = Conv2D(int(attention.shape[-1] / 2), kernel_size=(1, 1), strides=1, padding='same')(attention)\n",
    "\n",
    "    gate = GlobalMaxPooling2D()(fused)\n",
    "    gate = Reshape((1, 1, gate.shape[-1]))(gate)\n",
    "    gate = Activation('sigmoid')(gate)\n",
    "\n",
    "    gated_low = Multiply()([low_x, gate])\n",
    "    output = Add()([gated_low, high_x])\n",
    "    return output\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = DynamicSnakeConv2D(filters, 3)(x)\n",
    "    #x = DynamicSnakeConv2D(filters, 3)(x)\n",
    "\n",
    "    p = MaxPooling2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(x, skip, filters):\n",
    "    x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = fsf_block(skip, x)\n",
    "    #x = DynamicSnakeConv2D(filters, 3)(x) \n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = DynamicSnakeConv2D(filters, 3)(x)\n",
    "    return x\n",
    "\n",
    "# ------------------- Full U-Net Model -------------------\n",
    "def build_snake_gegenbauer_groupconv_unet(input_shape=(512, 512, 3), num_classes=1, filters=32):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    s1, p1 = encoder_block(inputs, filters)\n",
    "    s2, p2 = encoder_block(p1, filters * 2)\n",
    "    s3, p3 = encoder_block(p2, filters * 4)\n",
    "    s4, p4 = encoder_block(p3, filters * 8)\n",
    "\n",
    "    # Bottleneck\n",
    "    b1 = Conv2D(filters * 16, (3, 3), activation='relu', padding='same')(p4)\n",
    "    b1 = Conv2D(filters * 16, (3, 3), activation='relu', padding='same')(b1)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(b1, s4, filters * 8)\n",
    "    d2 = decoder_block(d1, s3, filters * 4)\n",
    "    d3 = decoder_block(d2, s2, filters * 2)\n",
    "    d4 = decoder_block(d3, s1, filters)\n",
    "\n",
    "    # Output\n",
    "    activation = 'sigmoid' if num_classes == 1 else 'softmax'\n",
    "    outputs = Conv2D(num_classes, (1, 1), padding='same', activation=activation)(d4)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# ------------------- Example -------------------\n",
    "model = build_snake_gegenbauer_groupconv_unet(input_shape=(512, 512, 3), num_classes=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define image dimensions\n",
    "desired_width = 512  # Replace with your desired width\n",
    "desired_height = 512  # Replace with your desired height\n",
    "batch_size = 32\n",
    "seed = 24\n",
    "\n",
    "# Create an ImageDataGenerator for images and masks without augmentation\n",
    "img_data_gen_args = dict(rescale=1/255.)\n",
    "\n",
    "mask_data_gen_args = dict(rescale=1/255., )  # Binarize the output\n",
    "\n",
    "# Generators for training, validation, and test data\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(image_dir, mask_dir, batch_size, target_size=(desired_width, desired_height)):\n",
    "    image_generator = image_data_generator.flow_from_directory(\n",
    "        image_dir,\n",
    "        target_size=target_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        seed=seed)\n",
    "\n",
    "    mask_generator = mask_data_generator.flow_from_directory(\n",
    "        mask_dir,\n",
    "        target_size=target_size,\n",
    "        color_mode='grayscale',\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        seed=seed)\n",
    "\n",
    "    return zip(image_generator, mask_generator)\n",
    "\n",
    "train_generator = create_generator('/home/jayakumar/road-extraction-main/data3/train_images/', '/home/jayakumar/road-extraction-main/data3/train_masks/', batch_size)\n",
    "val_generator = create_generator('/home/jayakumar/road-extraction-main/data3/val_images/', '/home/jayakumar/road-extraction-main/data3/val_masks/', batch_size)\n",
    "test_generator = create_generator('/home/jayakumar/road-extraction-main/data3/test_images/', '/home/jayakumar/road-extraction-main/data3/test_masks/', batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Images to confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def display_images(generator, num_images=3):\n",
    "#     for i in range(num_images):\n",
    "#         image, mask = next(generator)\n",
    "        \n",
    "#         # Display image\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.imshow(image[0])\n",
    "#         plt.title(\"Image\")\n",
    "        \n",
    "#         # Display mask\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.imshow(mask[0].squeeze(), cmap='gray')\n",
    "#         plt.title(\"Mask\")\n",
    "        \n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_images(train_generator, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, mask = next(train_generator)\n",
    "# print(\"Image datatype:\", image[0].dtype)\n",
    "# print(\"Mask datatype:\", mask[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, mask = next(train_generator)\n",
    "# print(type(image[0][0][0]))\n",
    "# print(mask[0][0][0])     #In other code, print(train_masks[0][0][0]) is giving 0.0 and type is <class 'numpy.float64'>, Here it is [0.] and type is <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_images(val_generator, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, mask = next(val_generator)\n",
    "# print(\"Image datatype:\", image[0].dtype)\n",
    "# print(\"Mask datatype:\", mask[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(image[0][0][0]))\n",
    "# print(mask[0][0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_images(test_generator, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, mask = next(test_generator)\n",
    "# print(\"Image datatype:\", image[0].dtype)\n",
    "# print(\"Mask datatype:\", mask[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(image[0][0][0]))\n",
    "# print(type(mask[0][0][0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('patchmodels/fkanunetadam32d24f6f6rsmitpatchba.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "def lr_scheduler(epoch,lr):\n",
    "    decay_rate=1e-6\n",
    "    return lr-decay_rate\n",
    "lr_callback=LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices=tf.compat.v1.config.experimental.list_physical_devices('GPU')\n",
    "print('GPU is available' if len(physical_devices) > 0 else 'Not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), loss=sm.losses.dice_loss, metrics=[sm.metrics.iou_score, sm.metrics.f1_score,sm.metrics.precision,sm.metrics.recall]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_imgs = len(os.listdir('/home/jayakumar/road-extraction-main/data3/train_images/train/'))\n",
    "steps_per_epoch = num_train_imgs // batch_size\n",
    "num_val_imgs = len(os.listdir('/home/jayakumar/road-extraction-main/data3/val_images/val/'))\n",
    "validation_steps = num_val_imgs // batch_size\n",
    "epochs = 100\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    #history = model.fit(train_images, train_masks, batch_size=4, epochs=epochs, validation_data=(val_images, val_masks), callbacks=[checkpoint,early_stopping,lr_callback])\n",
    "    history = model.fit(train_generator,validation_data=val_generator, steps_per_epoch=steps_per_epoch,validation_steps=validation_steps,epochs=epochs,callbacks=[checkpoint,early_stopping,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define folder and filename\n",
    "folder_path = 'patchhistory'\n",
    "filename = 'fkanunetadam32d24f6f6rsmitpatchba.pkl'  #Change filename everytime\n",
    "\n",
    "# Ensure the folder exists\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the training history\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# Later, load and plot the history\n",
    "with open(file_path, 'rb') as f:\n",
    "    loaded_history = pickle.load(f)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(loaded_history['loss'], label='Training Loss')\n",
    "plt.plot(loaded_history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "# load the saved model due to prior interuption\n",
    "model = load_model('patchmodels/fkanunetadam32d24f6f6rsmitpatchba.h5',custom_objects={'GegenbauerNeuralBlock': GegenbauerNeuralBlock},compile=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), loss=sm.losses.dice_loss, metrics=[sm.metrics.iou_score, sm.metrics.f1_score,sm.metrics.precision,sm.metrics.recall]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_images(test_generator, num_images=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Calculate the number of test images\n",
    "num_test_images = len(os.listdir('/home/jayakumar/road-extraction-main/data3/test_images/test/'))  # Update 'test' with the actual folder name inside 'test_images'\n",
    "\n",
    "# Calculate the number of steps\n",
    "steps = num_test_images // batch_size\n",
    "\n",
    "# Evaluate the model using the test generator\n",
    "eval = model.evaluate(test_generator, steps=steps+1)\n",
    "\n",
    "# Print the IoU score (or other metrics based on your model setup)\n",
    "print('Test IoU score: {:.2f}'.format(eval[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Calculate the number of test images\n",
    "num_test_images = len(os.listdir('/scratch/jayakumar/SC23D004/jkpatch/data3/test_images/test'))  # Update 'test' with the actual folder name inside 'test_images'\n",
    "\n",
    "# Calculate the number of steps\n",
    "steps = num_test_images // batch_size\n",
    "\n",
    "# Get a batch of test images and masks using the test generator\n",
    "test_images, test_masks = next(test_generator)\n",
    "print(len(test_images))\n",
    "\n",
    "# Select 10 random images for visualization\n",
    "random_indices = random.sample(range(0, len(test_images)), 8)\n",
    "test_sample = test_images[random_indices]\n",
    "ground_truth_sample = test_masks[random_indices]\n",
    "\n",
    "# Predict masks for the randomly selected images\n",
    "predictions = model.predict(test_sample)\n",
    "predictions = (predictions > 0.5).astype(np.uint8)\n",
    "\n",
    "# Set up a figure with 10 rows and 3 columns for the plots\n",
    "fig, axes = plt.subplots(8, 3, figsize=(8, 3*8))\n",
    "\n",
    "# Iterate over the random samples and display them\n",
    "for i in range(len(test_sample)):\n",
    "\n",
    "    image = (test_sample[i] * 255).astype(np.uint8)  # Rescale image to 0-255\n",
    "    mask = predictions[i]  # Predicted binary mask\n",
    "    ground_truth = ground_truth_sample[i]  # Ground truth binary mask\n",
    "\n",
    "    # Prepare overlay for predicted mask\n",
    "    overlay = image.copy()\n",
    "    mask = np.repeat(mask, 3, axis=2)  # Convert binary mask to 3 channels\n",
    "    inverted_mask = 1 - mask\n",
    "    yellow_mask = np.array([255, 255, 0]) * mask  # Use yellow color for mask\n",
    "\n",
    "    # Apply the mask to the image\n",
    "    result = image * inverted_mask + yellow_mask\n",
    "    alpha = 0.2\n",
    "    predicted_overlay = cv2.addWeighted(overlay, alpha, result.astype(overlay.dtype), 1 - alpha, 0)\n",
    "\n",
    "    # Plot the image, ground truth, and predicted mask\n",
    "    axes[i, 0].imshow(image)\n",
    "    axes[i, 0].set_title('Original')\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    axes[i, 1].imshow(ground_truth[:, :, 0], cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "    axes[i, 2].imshow(predicted_overlay)\n",
    "    axes[i, 2].set_title('Predicted')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "#plt.savefig('result.png', bbox_inches='tight')  # Save the figure as a PNG image\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
